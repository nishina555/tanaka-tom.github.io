{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning 第10回:\n",
    "# 　　　　　　パラメータの自動最適化(過学習編)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 今回の目標\n",
    "前回に引き続きパラメータの自動最適化  \n",
    "\n",
    "前回は以下の最適化を行った\n",
    "- パラメータ更新\n",
    "- 重みの初期値\n",
    "\n",
    "今回は特に過学習を抑制するためのパラメータ調整を紹介\n",
    "- Batch Normalization\n",
    "- 正則化\n",
    "- ハイパーパラメータの検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bach Normalization\n",
    "各層でのアクティベーション分布を正規化よって、適度な広がりを持つようにする  \n",
    "- 学習を速く進行させることができる(学習係数を大きくすることができる)\n",
    "- 初期値にそれほど依存しない(初期値に対してそこまで神経質にならなくてよい)\n",
    "- 過学習を抑制する\n",
    "\n",
    "Batch Normのレイヤを入れる\n",
    "![](https://tanaka-tom.github.io/update2/bach-norm-layer.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ { \\mu  }_{ B }\\leftarrow \\frac { 1 }{ m } \\sum _{ i=1 }^{ m }{ { x }_{ i } } $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ { { \\sigma  }_{ B }^{ 2 } }\\leftarrow \\frac { 1 }{ m } \\sum _{ i=1 }^{ m }{ { (x }_{ i } } -{ \\mu  }_{ B })^{ 2 } $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${ \\hat { x }  }_{ i }\\leftarrow \\frac { { x }_{ i }-{ \\mu  }_{ B } }{ \\sqrt { { \\sigma  }_{ B }^{ 2 }+\\varepsilon  }  } $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\varepsilon$ : 0徐算を防止のための小さい値(10e-7)\n",
    "- ${ \\mu  }_{ B }$ : 平均\n",
    "- ${ { \\sigma  }_{ B } }$ : 分散\n",
    "\n",
    "ミニバッチの入力データ $\\left\\{ { x }_{ 1 },{ x }_{ 2 },\\cdots ,{ x }_{ m } \\right\\} $ を  \n",
    "平均 0、分散 1 のデータ $ \\left\\{ { \\hat { x } }_{ 1 },{ \\hat { x } }_{ 2 },\\cdots ,{ \\hat { x } }_{ m } \\right\\} $  に変換する  \n",
    "この処理を活性化関数の前(もしくは後)に挿入し、データの分布の偏りを減らす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに Bach Normレイヤでは、正規化されたデータに対して固有のスケールとシフトで変換を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${ y }_{ i }\\leftarrow \\gamma { \\hat { x }  }_{ i }+\\beta $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma = 1,\\beta = 0$ からスタートして、学習によって適した値に調整される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正則化\n",
    "過学習抑制\n",
    "\n",
    "### 過学習の原因\n",
    "- パラメータを大量に持ち、表現力の高いモデルであること\n",
    "- 訓練データが少ないこと\n",
    "\n",
    "訓練データの正解率が100%付近に到達しても、テストデータの正解率が上昇しない場合には過学習の可能性が高い\n",
    "\n",
    "### Weight Decay\n",
    "大きな重みにペナルティを与える方法\n",
    "\n",
    "### Dropout\n",
    "ニューロンをランダムで削除する方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://tanaka-tom.github.io/update2/dropout.png)\n",
    "参照：　http://cs231n.github.io/neural-networks-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "\tdef __init__(self, dropout_ratio=0.5):\n",
    "\t\tself.dropout_ratio = dropout_ratio\n",
    "\t\tself.mask = None\n",
    "\n",
    "\tdef forward(self, x, train_flg=True):\n",
    "\t\tif train_flg:\n",
    "\t\t\tself.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "\t\t\treturn x * self.mask\n",
    "\t\telse:\n",
    "\t\t\treturn x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "\tdef backword(self, dout):\n",
    "\t\treturn dout * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータ検証\n",
    "\n",
    "### ステップ0\n",
    "ハイパーパラメータの範囲を設定する。\n",
    "### ステップ1\n",
    "設定されたハイパーパラメータの範囲から、ランダムにサンプリングする。\n",
    "### ステップ2\n",
    "ステップ1でサンプリングされたハイパーパラメータの値を使用して学習を行 い、検証データで認識精度を評価する(ただし、エポックは小さく設定)。\n",
    "### ステップ3\n",
    "ステップ1とステップ2をある回数(100 回など)繰り返し、それらの認識精 度の結果から、ハイパーパラメータの範囲を狭める。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
